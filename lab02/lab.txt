NOTE: I used the term "value" when talking about the return values of the evaluate function (or the y-axis values).
------------------------------------------------------------------------------------------------------------------------
Exercise 2.1
Run abs.py, an absolute value variant module and answer the following questions:

1. Which of the local search algorithms solves the problem? How well does each algorithm do?

ANSWER: Both algorithms solve the problem.

2. Which algorithm works more quickly?

ANSWER: Hill-climbing should be faster. The problem has one, obvious max value. So, the problem can be easily solved by
        following the "gradient" (the state with the highest value compared to the current state).

3. Does the starting value for x make any difference? Why or why not?

ANSWER: Since there's only one max value, the initial state should not make a difference.

4. What affect does changing the delta step value make on each algorithm? Why?

ANSWER: The delta value determines whether the search function chooses the next state.

5. What is the purpose of the exp_schedule() method in the simulated annealing function call?

ANSWER: It simulates the "temperature" and determines the likelihood of the function choosing a state with a value less
        than the current state.

------------------------------------------------------------------------------------------------------------------------
Exercise 2.2
Create a new module (sine.py), similar to the absolute value variant from exercise 2.1, that uses the sine function
variant specified above as its objective function. Get your new implementation running and then answer the following
(similar) questions:

1. How do each of the algorithms do on this problem space? Why?

ANSWER: Simulated annealing found a better solution.
    Hill-climbing finds the state closest to the initial state while having the highest possible value.
    Simulated annealing depended less on the initial state by occasionally choosing a random neighboring state for the
    next state.

2. Does the starting value make any difference here?

ANSWER:
    Hill-climbing - Since hill-climbing only chooses a neighbouring state with a higher value, and since sine is
    "periodic", the initial state determines how high the value of the final state can be.

    Simulated annealing solution - since the algorithm sometimes chooses a random next state, its less dependent on the
    initial state.

3. Does modifying the step size (i.e., delta) affect the operation of the two algorithms? Why or why not?

ANSWER: Increasing the step-size doesn't affect the performance of hill-climb while it significantly improves
    simulated-annealing's performance. This is because it lets the algorithm skip periods with a local maximum and
    explore other periods which may have higher maximum values.

    *NOTE: hill-climb never reaches a solution if the step-size is an non-zero, integer-multiple of pi. (It'll be in an
            infinite loop trying to achieve higher and higher values.)

4. What are the maximum and minimum possible values here, and how do the two algorithms score with respect to them?

ANSWER: The min possible y-value is 0. But, since the abs(x * sin(x)) is increasing, there is no maximum y-value.
    With higher step-sizes simulated-annealing usually performed better than hill-climb.
      e.g.
        Initial                      x: 5		            value: 4.794621373315692
        Hill-climbing solution       x: 5	                value: 4.794621373315692
        Simulated annealing solution x: 54.69911184307753	value: 52.587588933974295

------------------------------------------------------------------------------------------------------------------------
Exercise 2.3
Add code to your sine implementation (sine.py) that implements random restarts.

1. How does each algorithm do with these restarts? Why?

ANSWER: Hill-climbing achieves the solution sooner than Simulated annealing, while simulated annealing achieved a higher
    value. This may be because of the random behavior of simulated annealing.

2. What are the average values of the runs for each of the algorithms?

ANSWER:
    Hill-climbing solution       number of iterations: 78    x_val: 30   value: 29.640948722785854
    Simulated annealing soln     number of iterations: 91    x_val: 36   value: 35.704038723952166

3. If one of the algorithms does better, explain why; if not, explain why not.

ANSWER:
    Hill-climbing solution was generally better. The random restarts will eventually put initial state in a range where
    there is a local maximum that meets the goal state requirement. However, even if simulated-annealing can also benefit
    from similar randomness, the influence of the restarts are diminished by its random nature.

------------------------------------------------------------------------------------------------------------------------
Exercise 2.4
Consider the use of local beam search in which the successor states are chosen using one of the two algorithms as
applied to the abs-sin function.

1. For which algorithm does beam search make the most sense?

ANSWER:
    Local beam search makes the most sense for Simulated-annealing. Hill-climbing search's performance depends
    significantly on the initial state. So, after choosing the first set of initial states at random, the next best
    states would be ones neighboring an initial state with a maximum value. So, the answer quickly converges to a value
    that has the highest local maximum without actually being the maximum value (the goal state). So, the randomness
    (even if its limited) of simulated-annealing may help it get to even better states that are closer to the goal state.

2. How many solutions could you maintain with reasonable space and time constraints?

ANSWER: Since each state can only have two neighbours and we keep a fixed number of states, we can maintain a large
    number of solutions.

3. How would you modify the code to implement beam search? How is it different from random restarts, if at all?

ANSWER:
    In random restarts, each "run" is completely independent from the previous runs. But in beam search, the neighbours
    of the current state (including the initial state) are polled to find the next best states.

    So, I would change code in order to:
        Generate x-number of initial states and save them as current states;
    --> generate all current states' neighbouring states;
        evaluate the values to find the K-best neighbours;
        keep the k-best neighbours as the current states;    # keep states with the highest values for hill-climb and
                                                             # occasionally choose states at random for
                                                             # simulated annealing
        if one of the current states is a goal state, return the state; otherwise, go to "-->"