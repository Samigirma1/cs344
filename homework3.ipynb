{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Samuel Zeleke - CS344 - Homework 3\n",
    "\n",
    "1. Compute the following values using the restaurant example.\n",
    "\n",
    "    The *information gain* provided by using the price attribute as the root of the decision tree. Is it more or less \n",
    "valuable than the type or patrons attributes computed in class?\n",
    "\n",
    "    ANSWER:\n",
    "        Gain(Price) = 1 - Remainder(A)\n",
    "                    = 1 - ((3/12) * B(1/3) + (2/12) * B(2/2) + (7/12) * B(3/7))\n",
    "                    = 1 - (0.25 * -((1/3) * lg(1/3) + (2/3) * lg(2/3))\n",
    "                           + (1/6) * -((2/2) * lg(2/2) + (0/2) * lg(0/2)) # 0*lg(0) is undefined. But, since the right\n",
    "                                                                          # limit of x*lg(x) as x approaches 0 is 0, \n",
    "                                                                          # 0*lg(0) ~ 0\n",
    "                           + (7/12) * -((3/7) * lg(3/7) + (4/7) * lg(4/7))\n",
    "                      )\n",
    "                    = 1 - (0.25 * -(-0.52832 -0.389975) + \n",
    "                            (1/6) * -(0) +   \n",
    "                            (7/12) * -(-0.52388 - 0.46135) \n",
    "                          )\n",
    "                    = 1 - 0.80429\n",
    "                    = 0.1957\n",
    "        - Since the gain for Patrons is greater than the gain for Price, asking about price is less valuable than asking \n",
    "        about Patrons.\n",
    "        - Since the gain for Price is greater than the gain for Type, its more valuable than Type.\n",
    "\n",
    "2. In class, we attempted to create by hand a neural network that computes the XOR function. If this was possible, see \n",
    "   if you can simplify the network we built. Consider relaxing the conventions of densely-connected, sequential layers. \n",
    "   If it was not possible, give a full explanation why it can’t be done.\n",
    "   \n",
    "   ANSWER:\n",
    "        The XOR function is not linearly separable. So the function can not be represented by a perceptron network. \n",
    "        Instead, we should use to units (nodes) that learn to label (0, 1) and (1, 0) separately. Since XOR function has\n",
    "        one output, we need another node in an output layer that aggregates the outputs of the nodes in the input layer.\n",
    "        \n",
    "        Since XOR(a, b) = OR(AND(a, ¬b), AND(¬a, b)), we need 2 nodes for the ANDs in the input layer and a node for the\n",
    "        OR in the output layer.\n",
    "\n",
    "3. Use Python/NumPy/Pandas/Keras to load and manipulate the Boston Housing Dataset as follows.\n",
    "\n",
    "    a. Compute the dimensions of the data structures. Include code to print these values.\n",
    "    \n",
    "       ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "training data    dimension: 2, shape: 404 x 13\n",
      "training targets dimension: 1, shape: 404\n",
      "test data        dimension: 2, shape: 102 x 13\n",
      "test targets     dimension: 1, shape: 102\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "    \n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n",
    "\n",
    "print(\"training data    dimension: %d, shape: %d x %d\" %(train_data.ndim, train_data.shape[0], train_data.shape[1]))\n",
    "print(\"training targets dimension: %d, shape: %d\" %(train_targets.ndim, train_targets.shape[0]))\n",
    "print(\"test data        dimension: %d, shape: %d x %d\" %(test_data.ndim, test_data.shape[0], test_data.shape[1]))\n",
    "print(\"test targets     dimension: %d, shape: %d\" %(test_targets.ndim, test_targets.shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python3    \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    b. Construct a suitable testing set, training set, and validation set for this data. Submit code to create these \n",
    "       datasets but do not include the datasets themselves.\n",
    "       \n",
    "       ANSWER:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-67a304c07a9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_training_and_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error"
    }
   ],
   "source": [
    "import pandas\n",
    "import math\n",
    "\n",
    "def create_training_and_validation(taining, ratio = 0.3):\n",
    "    \n",
    "    training_set = pandas.DataSet()\n",
    "    validation_set = pandas.DataSet()\n",
    "    \n",
    "    return training_set, validation_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python3    \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    c. Create one new synthetic feature that could be useful for machine learning in this domain. Explain what it is and\n",
    "       why it might be useful, and submit code to add it to the dataset.\n",
    "       \n",
    "       ANSWER:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python3    \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-eb739bdf",
   "language": "python",
   "display_name": "PyCharm (CS344)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}