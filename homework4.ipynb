{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Samuel Zeleke, Neural Networks — Homework 4\n",
    "\n",
    "**QUESTION 1.** Speculate on whether you believe that so-called “deep” neural networks are destined to be another bust just as perceptrons and expert systems were in the past, or whether they really are a breakthrough that will be used for years into the future. Please give a two-to-three-paragraph answer, including examples to back up your argument.\n",
    "\n",
    "   **ANSWER**\n",
    "\n",
    "I believe the Deep neural networks are a breakthrough that will be around for a while. The failure of previous generations\n",
    "of AI is because they have significant problems in their functionality: Perceptrons didn't have the an efficient/automatic\n",
    "(back-propagation) algorithm that would adjust the weights across several layers; and Expert systems were hard to \"train\"\n",
    "and bad at the inferring output for new data.\n",
    "\n",
    "Deep neural networks don't have these issues. The introduction of CNNs have also greatly improved their performance. The\n",
    "only limiting factor I see is hardware limitations. The rate of performance improvements in newer generations of\n",
    "GPUs/CPUs (RIP Moore's law) is not as fast as the growth in the size of newer, more general models. So, if there is no\n",
    "\n",
    "\n",
    "**QUESTION 2.** Hand-compute a single, complete back-propagation cycle. Use the example network from class and compute the updated weight values for the first gradient descent iteration for the XOR example, i.e., [1, 1] → 0. Use the same initial weights we used in the class example but assume the identity function as the activation function (f(x) = x).\n",
    "\n",
    "**ANSWER**\n",
    "\n",
    "Inputs| $i_{1} = 1; i_{2} = 1$\n",
    "-------|-----------\n",
    "Hidden Layer | $W_{i_{1}h_{1}} = 0.11$; $W_{i_{1}h_{2}} = 0.12$; $W_{i_{2}h_{1}} = 0.21$; $W_{i_{2}h_{2}} = 0.08$\n",
    "Output Layer | $W_{h_{1}Output} = 0.14$; $W_{h_{2}Output} = 0.15$\n",
    "Learning Rate (lr) | $$0.05$$\n",
    "\n",
    "$$Output = \\begin{bmatrix} 1 & 1 \\end{bmatrix}\\begin{bmatrix} 0.11 & 0.12 \\\\ 0.21 & 0.08 \\end{bmatrix}\\begin{bmatrix} 0.14 \\\\ 0.15 \\end{bmatrix}$$\n",
    "$$= \\begin{bmatrix} 0.32 & 0.2 \\end{bmatrix}\\begin{bmatrix} 0.14 \\\\ 0.15 \\end{bmatrix} = 0.0748$$\n",
    "\n",
    "$$\\Delta_{error} = |0 - 0.0748| = 0.0748$$\n",
    "\n",
    "New values\n",
    "\n",
    "\n",
    "Output layer\n",
    "\n",
    "$W_{h_{1}Output}^{*} = W_{h_{1}Output} + lr * a_{1} * W_{h_{1}Output} * \\Delta_{error} = 0.14 + 0.05 * 0.32 * 0.0757 = 0.1412112$\n",
    "\n",
    "$W_{h_{2}Output}^{*} = W_{h_{2}Output} + lr * a_{2} * W_{h_{2}Output} * \\Delta_{error} = 0.15 + 0.05 * 0.2 * 0.0757 = 0.15076$\n",
    "\n",
    "Hidden layer\n",
    "\n",
    "$W_{i_{1}h_{1}}^{*} = W_{i_{1}h_{1}} + lr * i_{1} * W_{h_{1}Output} * \\Delta_{error} = 0.11 + 0.05 * 1 * 0.14 * 0.0757 = 0.1105299$\n",
    "\n",
    "$W_{i_{1}h_{2}}^{*} = W_{i_{1}h_{2}} + lr * i_{1} * W_{h_{2}Output} * \\Delta_{error} = 0.12 + 0.05 * 1 * 0.15 * 0.0757 = 0.1205676$\n",
    "\n",
    "$W_{i_{2}h_{1}}^{*} = W_{i_{2}h_{1}} + lr * i_{2} * W_{h_{1}Output} * \\Delta_{error} = 0.21 + 0.05 * 1 * 0.14 * 0.0757 = 0.2105299$\n",
    "\n",
    "$W_{i_{2}h_{2}}^{*} = W_{i_{2}h_{2}} + lr * i_{2} * W_{h_{2}Output} * \\Delta_{error} = 0.08 + 0.05 * 1 * 0.15 * 0.0757 = 0.0805676\\\\\\\\$\n",
    "\n",
    "\n",
    "\n",
    "**QUESTION 3.** Build a Keras-based ConvNet for Keras’s Fashion MNIST dataset (fashion_mnist). Experiment with different network architectures, submit your most performant network, and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import files\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.datasets\n",
    "from keras.optimizers import RMSprop, Adagrad\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get data\n",
    "(training_images, training_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noralize data\n",
    "training_images = training_images.astype(\"float32\") / 255.0\n",
    "test_images = test_images.astype(\"float32\") / 255.0\n",
    "training_images = training_images.reshape((training_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "#---Make labels categorical\n",
    "training_labels = keras.utils.to_categorical(training_labels)\n",
    "test_labels = keras.utils.to_categorical(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create network\n",
    "model = keras.Sequential()\n",
    "\n",
    "# input and first convolution: extract 30 features\n",
    "model.add(keras.layers.Conv2D(30, 2, activation=\"relu\", input_shape = (28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# input and second convolution: extract 30 features\n",
    "model.add(keras.layers.Conv2D(60, 3, activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "# input and third convolution: extract 30 features\n",
    "model.add(keras.layers.Conv2D(60, 3, activation=\"relu\", input_shape = (28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D(2))\n",
    "\n",
    "#flatten\n",
    "model.add(keras.layers.Flatten())\n",
    "# three dense layers\n",
    "# model.add(keras.layers.Dense(750, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(120, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(30, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer=Adagrad(learning_rate=0.006), metrics = [\"acc\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train\n",
    "history = model.fit(\n",
    "    training_images[:30000],\n",
    "    keras.utils.to_categorical(training_labels[:30000]),\n",
    "    epochs = 20,\n",
    "    validation_split=0.2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluate on test\n",
    "model.evaluate(\n",
    "    x = test_images[:250],\n",
    "    y = test_labels[:250],\n",
    "    steps = 10\n",
    ")\n",
    "# final lose = 0.008"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% python\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-eb739bdf",
   "language": "python",
   "display_name": "PyCharm (CS344)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}